---
title: "Regresiones (parte 2)"
author: "Rodrigo Zepeda"
date: "`r Sys.Date()`"
format: html
editor: visual
output:
  tufte::tufte_html: 
    tufte_features: ["fonts", "background","italics"]
    toc: false
    includes:
      in_header: javascriptcall.html
    css: style.css
  tufte::tufte_handout:
    citation_package: natbib
    latex_engine: xelatex
  tufte::tufte_book:
    citation_package: natbib
    latex_engine: xelatex
bibliography: skeleton.bib
link-citations: yes
editor_options: 
  chunk_output_type: console
---

::: callout-warning
Si no lo has leído aún ve la [parte 1 de regresiones](https://rodrigozepeda.github.io/CursoR/Regresiones1.html)
:::

## Paquetes y datos a utilizar

A lo largo de esta sección usaremos los siguientes paquetes:

```{r}
#| warning: false
#| output: false
library(tidyverse)
library(tidymodels)
library(ggfortify) #autoplot para diagnósticos
library(rstanarm) #para bayesiana
library(poissonreg) #modelo Poisson

#Siempre que uses tidymodels
tidymodels_prefer()
```

En general usaremos la filosofía `tidymodels` para combinar los resultados con el `tidyverse`. Si quieres saber más de `tidymodels` te recomiendo checar [su libro](https://www.tmwr.org) o [su página web](https://www.tidymodels.org/learn/).

# Modelos lineales generalizados

## Regresión Poisson (conteo)

Anteriormente planteamos el modelo

$$
y \sim \textrm{Normal}(\beta_0 + \beta_1 x, \sigma^2)
$$

podemos cambiar la distribución normal por una Poisson si tenemos datos de conteo, por ejemplo:

$$
y \sim \textrm{Poisson}(\beta_0 + \beta_1 x)
$$

¡Y ya tenemos una regresión Poisson! Ésta no es la clásica pues es bien difícil de controlar numéricamente. La Poisson clásica tiene una exponencial adentro:

$$
y \sim \textrm{Poisson}\big(\exp(\beta_0 + \beta_1 x)\big)
$$

Usaremos esta última para los modelos. Para ello nos apoyaremos del `engine` de `glm` (por generalized linear model)

Para los datos usaremos la información de *Generalized Linear Models for Cross-Classified Data from the WFS. World Fertility Survey Technical Bulletins* . Podemos leerlos como sigue:

```{r}
#| warning: false
niños <- read_table("https://data.princeton.edu/wws509/datasets/ceb.dat",
                        skip = 1, col_names = F) 
colnames(niños) <- c("Fila",  "dur", "res", "educ", "mean", "var", "n", "y")
niños <- niños %>% mutate(y = round(y))
```

La base contiene la `dur` la duración del matrimonio, `res` la residencia (suva, urbano y rural), el nivel educativo `educ`, la media y la varianza del número de niños nacidos y `n` la cantidad de mujeres en cada grupo. La variable `y` contiene el producto de `mean*n` para obtener el total de niños nacidos para todas las mujeres en cada grupo.

Podemos especificar fácilmente un modelo Poisson para los conteos:

```{r}
modelo_poisson <- poisson_reg() %>%
  set_engine("glm") %>%
  fit(y ~ educ, data = niños)
```

podemos obtener el summary:

```{r}
modelo_poisson %>%
  extract_fit_engine() %>%
  summary()
```

o crear un `tibble`:

```{r}
modelo_poisson %>%
  extract_fit_engine() %>%
  tidy()
```

o también podemos ajustarlo de manera bayesiana:

```{r}
#| message: false
#| results: hide
poisson_reg() %>%
  set_engine("stan") %>%
  fit(y ~ educ, data = niños) %>%
  extract_fit_engine() %>%
  summary()
```

Podemos agregar más factores a nuestra regresión. Para ello vale la pena recordar las fórmulas de `R`:

| Fórmula       | Significado                                                                                                                     |
|--------------|----------------------------------------------------------|
| `1`           | El intercepto                                                                                                                   |
| `+x`          | Agregar la variable `x` a la regresión                                                                                          |
| `-x`          | Quitar la variable `x` de la regresión                                                                                          |
| `x1:x2`       | Interacción entre `x1` y `x2`                                                                                                   |
| `x1*x2`       | Cruzamiento es lo mismo que poner `x1 + x2 + x1:x2`                                                                             |
| `I()`         | Se utiliza para realizar operaciones aritméticas adentro. Por ejemplo generar una variable que sea `x1+ x2 haciendo I(x1 + x2)` |
| `(x | grupo)` | Modelos mixtos donde la pendiente de `x` depende del grupo (efectos aleatorios)                                                 |

En nuestro modelo podemos incluir otras variables (digamos la residencia) agregándolas con suma:

```{r}
poisson_reg() %>%
  set_engine("glm") %>%
  fit(y ~ educ + res, data = niños) %>%
  extract_fit_engine() %>%
  summary()
```

La educación, sin embargo, es una variable ordinal donde `No educación` es menor que `Sec+` y es menor que `Upper`. Para ello podemos convertir la variable a factor y especificar el orden:

```{r}
niños <- niños %>%
  mutate(edf = factor(educ, levels = c("none","lower", "sec+","upper"),
                            ordered = T))
poisson_reg() %>%
  set_engine("glm") %>%
  fit(y ~ edf + res, data = niños) %>%
  extract_fit_engine() %>%
  summary()
```

Podemos agregar también la interacción entre educación y residencia:

```{r}
poisson_reg() %>%
  set_engine("glm") %>%
  fit(y ~ edf + res + edf:res, data = niños) %>%
  extract_fit_engine() %>%
  summary()
```

que es lo mismo que el operador de cruzamiento `*`:

```{r}
poisson_reg() %>%
  set_engine("glm") %>%
  fit(y ~ edf * res, data = niños) %>%
  extract_fit_engine() %>%
  summary()
```

En los modelos de Poisson es usual usar un `offset` dado por el tamaño de la población. Si el `offset` es $\lambda$ el modelo se ve como:

$$
y \sim \textrm{Poisson}\big(\lambda\cdot \exp(\beta_0 + \beta_1 x)\big)
$$

Usualmente el `offset` es `log(n)` donde `n` es el tamaño de la población. Esto se escribe como:

```{r}
niños <- niños %>%
  mutate(logn = log(n))

poisson_reg() %>%
  set_engine("glm") %>%
  fit(y ~ edf * res + offset(logn), data = niños) %>%
  extract_fit_engine() %>%
  summary()
```

### Ejercicios

1.  Utilice los datos en la [siguiente página](https://data.princeton.edu/wws509/datasets/#smoking). Determine si hay una asociación entre el consumo de cigarros, pipas y puros y la muerte.

2.  Utilice los datos en la [siguiente página](https://data.princeton.edu/wws509/datasets/#cancer). Determine si la edad influye en la supervivencia de los tuomores.

## Regresión logística y probit

En las regresiones logística y probit el planteamiento es similar sólo que se utilizan para respuestas binarias (0 ó 1). En este caso los modelos son:

$$
y \sim \textrm{Bernoulli}\big(\textrm{logit}(\beta_0 + \beta_1 x)\big)
$$

con

$$
\textrm{logit}(p) = \frac{p}{1-p}
$$

y

$$
y \sim \textrm{Bernoulli}\big(\Phi(\beta_0 + \beta_1 x)\big)
$$ donde $\Phi$ es la función de distribución acumulada de una normal. En ambos casos la especificación es similar:

```{r}
anticonceptivos <- read_table("https://data.princeton.edu/wws509/datasets/cuse.raw",
                              skip = 0, col_names = F) %>% uncount(X5)

colnames(anticonceptivos) <- c("age", "education", "wants_more_children",
                               "using_contraceptive")

anticonceptivos <- anticonceptivos %>%
  mutate(
    age = case_when(
      age == 1 ~ "<25",
      age == 2 ~ "25-29", 
      age == 3 ~ "30-39", 
      age == 4 ~ "40-49"
    )
  ) %>%
  mutate(education = if_else(education == 0, "None", "Some")) %>%
  mutate(wants_more_children = if_else(wants_more_children == 0, "No", "More")) %>%
  mutate(usa_anticonceptivo = factor(using_contraceptive, 
                                      levels = c(0,1), labels = c("No","Yes"))) 
```

Podemos checar si la gente está usando o no anticonceptivos en función del grupo de edad con una regresión logística:

```{r}
modelo_logit <- logistic_reg() %>%
  set_engine("glm") %>%
  fit(usa_anticonceptivo ~ age + education, data = anticonceptivos) 
```

donde podemos ver sus estadísticas por ejemplo con `tidy`:

```{r}
modelo_logit %>%
  extract_fit_engine() %>%
  tidy(conf.int = T, exponentiate = T)
```

De hecho la logística es sólo un tipo de lineal por lo cual puede hacerse así:

```{r}
linear_reg() %>%
  set_engine("glm", family = binomial(link = "logit")) %>%
  fit(using_contraceptive ~ age + education, data = anticonceptivos) %>%
  extract_fit_engine() %>%
  summary()
```

Podemos ponerla directo en `Word`:

```{r}
library(gtsummary)
library(flextable)

linear_reg() %>%
  set_engine("glm", family = binomial(link = "logit")) %>%
  fit(using_contraceptive ~ age + education, data = anticonceptivos) %>%
  extract_fit_engine() %>%
   tbl_regression(exponentiate = TRUE) %>%
   as_flex_table() %>%
   save_as_docx(path = "Tabla.docx")
```

[Acá](https://www.danieldsjoberg.com/gtsummary/) hay más opciones para personalizar tu tabla de Word. **Ojo** `tbl_regression` sólo está disponible para los modelos que aparecen [en la tabla](https://www.danieldsjoberg.com/gtsummary/articles/tbl_regression.html)

O bien una probit sólo cambiando el modelo:

```{r}
linear_reg() %>%
  set_engine("glm", family = binomial(link = "probit")) %>%
  fit(using_contraceptive ~ age + education, data = anticonceptivos) %>%
  extract_fit_engine() %>%
  summary()
```

### Ejercicio

1.  Descargue la base de datos disponible [en este link](https://github.com/jenineharris/logistic-regression-tutorial/blob/main/lab%202%20data.dta). La codificación de `imc` es `0` si normal o bajo y `1` si sobrepeso u obesidad. La variable `yearsSmoke` son los años que lleva la persona fumando cigarrillos y `lungCancer` es `1` si ha tenido un diagnóstico de cáncer de pulmón y `0` si no. Determine si los años que lleva fumando la persona influyen en el diagnóstico. ¿Qué dice la $R^2$ del ajuste?

2.  Repite el análisis de la base de anticonceptivos pero ahora con un modelo bayesiano (`stan`). ¿Qué dice el `loo`?

```{=html}
<!--
## Validación de una logística


http://www.sthda.com/english/articles/36-classification-methods-essentials/148-logistic-regression-assumptions-and-diagnostics-in-r
-->
```
# Regresión Multinomial

Mientras que una logística sirve para clasificar en dos categorías, una multinomial clasifica en múltiples. Leamos los datos:

```{r}
library(forcats) #para el as_factor
library(haven)
ml <- read_dta("https://stats.idre.ucla.edu/stat/data/hsbdemo.dta")

#Ponerle las etiquetas de stata
ml <- ml %>%
  mutate(across(c(female:prog, honors), ~ as_factor(.)))
```

en particular nos interesa estudiar el programa a partir de los valores de `ses` (nivel socioeconómico) y `write` (score de su ensayo)

```{r}
ml %>%
  group_by(ses, prog) %>%
  tally() %>%
  pivot_wider(id_cols = ses, names_from = prog, values_from = n)
```

Único cambio es ahora usar `multinom_reg` para la regresión y el `engine` default recomendado es `nnet` (ver más [acá](https://parsnip.tidymodels.org/reference/multinom_reg.html))

```{r}
modelo_multi <- multinom_reg() %>%
  set_engine("nnet") %>%
  fit(prog ~ ses + write, data = ml)
```

Y listo:

```{r}
modelo_multi  %>%
  extract_fit_engine() %>%
  tidy(exponentiate = TRUE) 
```

## Ejercicio

1.  Obtén la siguiente base de datos de pingüinos:

```{r}
library(palmerpenguins)
data(penguins)
pinguinos <- penguins
```

Construye un modelo para clasificar un pingüino según su especie (`species`). Utiliza el modelo para determinar la especie de los siguientes tres pingüinos:

```{r}
pinguinos_a_determinar <- tibble(
 island            = c("Torgersen","Torgersen","Dream"),
 bill_length_mm    = c(20, 18, 14),
 flipper_length_mm = c(180, 200, 190)
)
```

# Resumen y validación de predicciones

**Sección incompleta**

En muchos casos al hacer modelos predictivos lo que interesa es solamente si puedes predecir bien el caso. En ese sentido las métricas anteriores no son las mejores.

```{r}
#Nos interesa predecir diabetes
diabetes <- read_csv(file = "https://raw.githubusercontent.com/MicrosoftDocs/ml-basics/master/data/diabetes.csv")

#Limpiamos como factor diabetic
diabetes <- diabetes %>%
  mutate(Diabetic = factor(Diabetic, levels = c("1","0"),
                           labels = c("Diabetico","No diabético"))) %>% 
  select(-PatientID)
```

Visualización:

```{r}
# Pivot data to a long format
diabetes_select_long <- diabetes %>% 
    pivot_longer(!Diabetic, names_to = "features", values_to = "values")

ggplot(diabetes_select_long, 
       aes(x = Diabetic, y = values, fill = features)) +
  geom_boxplot() + 
  facet_wrap(~ features, scales = "free", ncol = 4) +
  scale_color_viridis_d(option = "plasma", end = .7) +
  theme(legend.position = "none") +
  theme_light()
```

Comenzamos dividiendo los datos

```{r}
#Seleccionamos 70% para entrenar (usualmente 70-80)
set.seed(2056)
diabetes_split <- diabetes %>% 
  initial_split(prop = 0.70)

diabetes_train <- training(diabetes_split)
diabetes_test  <- testing(diabetes_split)
```

Construimos el modelo:

```{r}
modelo_logreg <- logistic_reg() %>% 
  set_engine("glm") 
```

Ajustamos:

```{r}
logreg_fit <- modelo_logreg %>% 
  fit(Diabetic ~ ., data = diabetes_train) #. significa vs todos
```

Checamos contra los observados:

```{r}
predichos <- logreg_fit %>% 
  predict(new_data = diabetes_test)

results <- diabetes_test %>% 
  select(Diabetic) %>% 
  bind_cols(predichos)
```

Midamos precisión (positive predictive value), accuracy, sensibilidad (recall), especificidad:

```{r}
# Combine metrics and evaluate them all at once
eval_metrics <- metric_set(precision, sensitivity, 
                           accuracy, specificity)
eval_metrics(data = results, truth = Diabetic, estimate = .pred_class)
```

También podemos sacar la matriz de confusión:

```{r}
conf_mat(data = results, truth = Diabetic, estimate = .pred_class)
```

También podemos armar nuestra curva `roc`:

```{r}
predice_proba <- logreg_fit %>% 
              predict(new_data = diabetes_test, type = "prob")

results <- results %>% 
  bind_cols(predice_proba)
```

```{r}
results %>%
  roc_curve(truth = Diabetic, .pred_Diabetico) %>% 
  autoplot()
```

## Ejercicio

1.  Construye tres modelos distintos para predecir diabetes a partir de los siguientes datos **sin usar la variable `glucose`**:

```{r}
library(mlbench)
data(PimaIndiansDiabetes)
diabedatos <- PimaIndiansDiabetes
```

Tus modelos pueden ser logísticos pero al menos uno de los tres que sea un árbol en `mode = "classification"` (opciones: [`bart`](https://parsnip.tidymodels.org/reference/bart.html), [`random_forest`](https://parsnip.tidymodels.org/reference/rand_forest.html), [`boost_tree`](https://parsnip.tidymodels.org/reference/boost_tree.html), [`decision_tree`](https://parsnip.tidymodels.org/reference/decision_tree.html), [`bag_tree`](https://parsnip.tidymodels.org/reference/bag_tree.html))

Utiliza métricas (como sensibilidad, especificidad, etc) sobre el para decidir cuál es el mejor modelo.

# Series de tiempo

**Sección incompleta**

## Análisis preliminar

```{r}
library(modeltime)
library(timetk)
library(lubridate)
```

Casos de campylobacter en Alemania (copia y pega)

```{r}
library(readxl)
url <- "https://github.com/epirhandbook/Epi_R_handbook/raw/master/data/time_series/campylobacter_germany.xlsx"
destfile <- "campylobacter_germany.xlsx"
curl::curl_download(url, destfile)
campylobacter_germany <- read_excel(destfile)
```

Veamos la info:

```{r}
ggplot(campylobacter_germany) +
  geom_line(aes(x = date, y = case)) +
  theme_light()
```

Otra forma:

```{r}
campylobacter_germany %>%
  plot_time_series(date, case, .interactive = T)
```

Partes de una serie de tiempo clásica:

```{r}
campylobacter_germany %>% 
  plot_acf_diagnostics(date, case, .interactive = T, .lags = 52)
```

```{r}
campylobacter_germany %>% 
  plot_seasonal_diagnostics(date, case, .interactive = T)
```

```{r}
campylobacter_germany %>% 
  plot_stl_diagnostics(date, case, .interactive = F)

#Como no se ve completo
ggsave("Diags.pdf", width = 10, height = 25)
```

## Modelos

En esta sección haremos `arima_reg()` y `linear_reg()`. En teoría el `arima` debería ser mejor que una regresión lineal.

```{r}
#Para decidir el modelo primero obtenemos splits
splits <- initial_time_split(campylobacter_germany, prop = 0.8)

entrena <- training(splits)
testea  <- testing(splits)

#Ajuste de un ARIMA
modelo_ARIMA <- arima_reg() %>%
    set_engine(engine = "auto_arima") %>%
    fit(case ~ date + factor(month(date, label = TRUE), 
                             ordered = FALSE), data = entrena)

#Regresión lineal con mes como cofactor
model_lm <- linear_reg() %>%
    set_engine("lm") %>%
    fit(case ~ as.numeric(date) + 
          factor(month(date, label = TRUE), ordered = FALSE),
        data = entrena)

#Junto mis modelos
models_tbl <- modeltime_table(
  modelo_ARIMA, model_lm
)

#Veo contra el test
calibration_tbl <- models_tbl %>%
    modeltime_calibrate(new_data = testea)

#Veo
calibration_tbl %>%
   modeltime_forecast(
        new_data    = testea,
        actual_data = campylobacter_germany
    ) %>%
    plot_modeltime_forecast(
      .interactive      = T
    )

#Tabulo métricas
calibration_tbl %>%
    modeltime_accuracy() %>%
    table_modeltime_accuracy(
        .interactive = T
    )

#Reajuste y predicción del futuro
refit_tbl <- calibration_tbl %>%
    modeltime_refit(data = campylobacter_germany)

futuro <- refit_tbl %>%
    modeltime_forecast(h = "3 years", 
                       actual_data = campylobacter_germany) 

futuro %>%
  filter(.model_desc != "UPDATE: REGRESSION WITH ARIMA(3,1,0)(0,0,1)[13] ERRORS") %>%
    plot_modeltime_forecast(
      .interactive      = T
    )
```

## Ejercicio

La siguiente base de datos contiene los registros de dengue en México de 2017 a la fecha. Las variables son `fecha` (proxy de semana epidemológica) y `nraw` (casos de dengue en la semana). `n` es un suavizamiento con media móvil, `logn` y `log_nraw` representan los logaritmos de la media móvil `n` y de `nraw` respectivamente. **Las variables `t` y `n.value` se deben ignorar.**

> Ajuste al menos dos modelos distintos uno de ellos `prophet_reg` para determinar cuántos casos de dengue habrán hasta que termine el año.

```{r}
dengue <- read_csv("https://media.githubusercontent.com/media/RodrigoZepeda/DengueMX/lognormal/datos-limpios/dengue_for_model_mx.csv") %>%
  filter(fecha >= as.Date("2017/01/01"))
```

# Sistema

```{r}
sessioninfo::session_info()
```
